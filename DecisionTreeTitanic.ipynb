{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEntropy(data,Y,X=None,Xgiven=None):\n",
    "    ''' \n",
    "    Calculates the conditional entropyies of the form H(Y), H(Y|X), H(Y|X1=x1,...,Xj=xj) and H(Y|Xi=xi,Xj=xj,X)\n",
    "    INPUT: data : mxn numpy array of data\n",
    "            Y: Index of the target vairable. 0<=Y<n\n",
    "            X: The conditional vairable. 0<=X<n\n",
    "            Xgiven = [(X1,x1),(X2,x2),....,(Xj,xj)]\n",
    "    OUTPUT: H(Y|Xi=xi,...,Xj=xj,X)\n",
    "    '''\n",
    "    Ndata = data.shape[0]\n",
    "    Yvalues = np.unique(data[:,Y])\n",
    "    N_Yvalues = Yvalues.size\n",
    "    \n",
    "    if X==None and Xgiven==None: # Calculate the self-entropy H(Y)\n",
    "        N=Ndata\n",
    "        pYgivenX = np.zeros(N_Yvalues)\n",
    "        for i in range(N_Yvalues):\n",
    "            pYgivenX[i] = ((data[:,Y]==Yvalues[i]).sum())/N       \n",
    "        HY = -pYgivenX.dot(np.log2(pYgivenX))\n",
    "    elif Xgiven == None and X!=None: # Calculate simple conditional-entropy, H(Y|X)\n",
    "        Xvalues = np.unique(data[:,X])\n",
    "        N_Xvalues = Xvalues.size\n",
    "        HY_givenX = np.zeros(N_Xvalues)\n",
    "        pX = np.zeros(N_Xvalues)\n",
    "\n",
    "        for i in range(N_Xvalues):            \n",
    "            data_givenX = data[(data[:,X]==Xvalues[i])]\n",
    "            pX[i] = ((data[:,X]==Xvalues[i]).sum())/Ndata\n",
    "            Nx = data_givenX.shape[0]\n",
    "            pYgivenX = np.zeros(N_Yvalues)\n",
    "            for j in range(N_Yvalues):\n",
    "                pYgivenX[j] = ((data_givenX[:,Y]==Yvalues[j]).sum())/Nx\n",
    "            \n",
    "            with np.errstate(divide='ignore'):\n",
    "                logProb = np.log2(pYgivenX)\n",
    "            logProb[np.isneginf(logProb)]=0\n",
    "            HY_givenX[i] = -pYgivenX.dot(logProb)\n",
    "        \n",
    "        HY = pX.dot(HY_givenX)\n",
    "    \n",
    "    elif Xgiven!=None and X==None:# Calculate the conditional-entropy given some observations H(Y|X1=x1,...Xn=x)        \n",
    "        HY_givenX = 0        \n",
    "        data_filtered = data\n",
    "        for x_given in Xgiven:\n",
    "            data_temp = data_filtered[(data_filtered[:,x_given[0]]==x_given[1])]    \n",
    "            data_filtered = data_temp        \n",
    "        Ndata = data_filtered.shape[0]                                \n",
    "        pYgivenX = np.zeros(N_Yvalues)\n",
    "        \n",
    "        for i in range(N_Yvalues):\n",
    "            pYgivenX[i] = ((data_filtered[:,Y]==Yvalues[i]).sum())/Ndata\n",
    "        \n",
    "        with np.errstate(divide='ignore'):\n",
    "            logProb = np.log2(pYgivenX)\n",
    "        logProb[np.isneginf(logProb)]=0\n",
    "        HY_givenX = -pYgivenX.dot(logProb)\n",
    "        \n",
    "        HY = HY_givenX\n",
    "                \n",
    "    \n",
    "    else:# Calculate the conditional-entropy H(Y|Xi=xi,...,X)        \n",
    "        Xvalues = np.unique(data[:,X])\n",
    "        N_Xvalues = Xvalues.size\n",
    "        HY_givenX = np.zeros(N_Xvalues)\n",
    "        pX = np.zeros(N_Xvalues)\n",
    "\n",
    "        data_filtered = data\n",
    "        for x_given in Xgiven:\n",
    "            data_temp = data_filtered[(data_filtered[:,x_given[0]]==x_given[1])]    \n",
    "            data_filtered = data_temp\n",
    "        \n",
    "        Ndata = data_filtered.shape[0]        \n",
    "        for i in range(N_Xvalues):                          \n",
    "            data_givenX = data_filtered[(data_filtered[:,X]==Xvalues[i])]\n",
    "            pX[i] = ((data_filtered[:,X]==Xvalues[i]).sum())/Ndata\n",
    "            Nx = data_givenX.shape[0]            \n",
    "            pYgivenX = np.zeros(N_Yvalues)\n",
    "            for j in range(N_Yvalues):                \n",
    "                if Nx == 0 :\n",
    "                    pYgivenX[j]=0\n",
    "                else:\n",
    "                    pYgivenX[j] = ((data_givenX[:,Y]==Yvalues[j]).sum())/Nx\n",
    "            \n",
    "            with np.errstate(divide='ignore'):\n",
    "                logProb = np.log2(pYgivenX)\n",
    "            logProb[np.isneginf(logProb)]=0\n",
    "            HY_givenX[i] = -pYgivenX.dot(logProb)\n",
    "        \n",
    "        HY = pX.dot(HY_givenX)\n",
    "        \n",
    "        \n",
    "                \n",
    "    return HY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRoot(data,labelId,cols):\n",
    "    '''\n",
    "    Finds the root feature for the decision tree\n",
    "    INPUT:  data - mxn numpy array of data , n = nFeatures + 1 (target)\n",
    "            labelId - the id of the target/label\n",
    "            cols - The names of all the n columns\n",
    "    OUTPUT: root- the id of the root feature\n",
    "    '''\n",
    "    HY = getEntropy(data,Y=labelId)\n",
    "    print('CONDITIONAL ENTROPIES: ')\n",
    "    print(f'H(Y): {HY}')\n",
    "    Nfeatures = len(cols)-1\n",
    "    HY_Given_Feature = np.zeros(Nfeatures)\n",
    "    for i in range(Nfeatures):\n",
    "        HY_Given_Feature[i] = getEntropy(data,Y=labelId,X=i)\n",
    "        print(f'H(Y|{columnNames[i]}) : {HY_Given_Feature[i]}')\n",
    "    \n",
    "    print('\\nINFORMATION GAINS: ')\n",
    "\n",
    "    for i in range(Nfeatures):    \n",
    "        print(f'I(Y;{cols[i]}) : {HY- HY_Given_Feature[i]}')\n",
    "\n",
    "    root = np.argmin(HY_Given_Feature)\n",
    "    print(f'root : {root}')\n",
    "    print(f'\\nRoot feature: {cols[root]}')\n",
    "    \n",
    "    return root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNextNode(data,currentNode,featureSpace,labelId,treeChildren):\n",
    "    '''\n",
    "    Given filtered data and a feature/node, finds the next features in the decision tree for all values of the node/feature\n",
    "    INPUT:  data - mxn numpy array of filtered data , n = nFeatures + 1 (target)\n",
    "            currentNode - this is the feature/node where we are currently. The tree has been built for all levels above this node.\n",
    "            labelId - the id of the target/label\n",
    "            cols - The names of all the n columns\n",
    "    OUTPUT: treeChildren - the coded version of the tree.\n",
    "            treeChildren[currentNode][i] = j if feature j is the next feature when currentNode = i, given the path from the root of the tree to currentRoot\n",
    "            treeChildren[currentNode][i] = +-111 if the target label is 1/0 resp,when currentNode = i, given the path from the root of the tree to currentRoot\n",
    "            treeChildren[currentNode][i] = -1 if currentNode does not take the value i\n",
    "    '''\n",
    "    Nfeatures = len(featureSpace)\n",
    "    remainingFeatures = list(range(Nfeatures))\n",
    "    remainingFeatures.remove(currentNode)\n",
    "    for i in range(len(featureSpace[currentNode])):\n",
    "        print(f'\\nFINDING THE NEXT FEATURE TO CHECK AFTER {columnNames[currentNode]}={featureSpace[currentNode][i]}')\n",
    "        currentNodeValues = featureSpace[currentNode]\n",
    "        NcurrentFatures = len(currentNodeValues)\n",
    "        given=[(currentNode,i)]        \n",
    "        HY = getEntropy(data,Y=labelId,X=None,Xgiven=given)\n",
    "        M=100\n",
    "        HY_Given_Feature = M*np.ones(len(remainingFeatures))\n",
    "        print('CONDITIONAL ENTROPIES: ')\n",
    "        print(f'H(Y|{columnNames[currentNode]} = {currentNodeValues[i]}): {HY}')\n",
    "        if HY>0:\n",
    "            for f in range(len(remainingFeatures)): \n",
    "                featureId = remainingFeatures[f]\n",
    "                HY_Given_Feature[f] = getEntropy(data,Y=4,X=featureId,Xgiven=given)\n",
    "                print(f'H(Y|{columnNames[currentNode]} = {currentNodeValues[i]},{columnNames[featureId]}) : {HY_Given_Feature[f]}')    \n",
    "    \n",
    "            print('INFORMATION GAINS: ')\n",
    "            for f in range(len(remainingFeatures)): \n",
    "                featureId = remainingFeatures[f]\n",
    "                print(f'I(Y;{columnNames[featureId]} = {currentNodeValues[i]},{columnNames[featureId]}) : {HY - HY_Given_Feature[f]}')\n",
    "        \n",
    "            nextNode = remainingFeatures[np.argmin(HY_Given_Feature)]\n",
    "            print(f'Next Node after {columnNames[currentNode]}= {featureSpace[currentNode][i]}: {columnNames[nextNode]} ')\n",
    "            treeChildren[currentNode,i] = nextNode\n",
    "    \n",
    "        elif HY==0:\n",
    "            m = np.argwhere(data[:,currentNode]==i)[0,0]\n",
    "            res = data[m,4]\n",
    "            print(f'Leaf node! Decision: {res}')\n",
    "            if res == 1:\n",
    "                treeChildren[currentNode,i] = 111\n",
    "            else:\n",
    "                treeChildren[currentNode,i] = -111\n",
    "    \n",
    "    return treeChildren     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x,root,children):\n",
    "    '''\n",
    "    returns a prediction based on an input instance x\n",
    "    INPUT: x- an instance\n",
    "           root - the root of the tree\n",
    "           children - the tree coded as a 2D nummpy array \n",
    "    OUTPUT: 0/1\n",
    "    '''\n",
    "    pred = None\n",
    "    while pred!=111 and pred!= -111:\n",
    "        res = int(children[root,x[root]])\n",
    "        if res == 111 or res == -111:\n",
    "            pred = res\n",
    "        else:\n",
    "            root = res\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getErrorRate(y_pred,y_actual):\n",
    "    '''Finds the rate of misclassification\n",
    "    '''\n",
    "    return (y_pred-y_actual).sum()/y_actual.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD AND FORMAT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"titanic.csv\"\n",
    "data = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's look at a few records to see what they look like - interested in finding out column names, feature types\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interested in feature types and range\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking correlations - Interested in choosing useful features\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for missing data\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Feature space for Sib/Spouse: {data[\"Siblings/Spouses Aboard\"].unique()}')\n",
    "print(f'Feature space for Par/Child: {data[\"Parents/Children Aboard\"].unique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrain = data['Survived'].to_numpy()\n",
    "PclassCol = data['Pclass'].apply(lambda X: X-1).to_numpy() #Mapping Pclass to 0,1,2\n",
    "siblings_or_spousesCol = data['Siblings/Spouses Aboard'].apply(lambda X: 1 if X>0 else 0).to_numpy()\n",
    "parents_or_childrenCol = data['Parents/Children Aboard'].apply(lambda X: 1 if X>0 else 0).to_numpy()\n",
    "sexCol = data['Sex'].apply(lambda X: 1 if X=='male' else 0).to_numpy()\n",
    "XTrain = np.column_stack((PclassCol,siblings_or_spousesCol,parents_or_childrenCol,sexCol))\n",
    "(m,n) = XTrain.shape\n",
    "print(f'(m,n): {(m,n)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.column_stack((XTrain,yTrain))\n",
    "columnNames = ['PClass','Siblings/Spouse','Parents/Children','Sex','Survived']\n",
    "featureSpace_1 = ['1','2','3']\n",
    "featureSpace_2 = ['None','>0']\n",
    "featureSpace_3 = ['None','>0']\n",
    "featureSpace_4 = ['Male','Female']\n",
    "featureSpace = [featureSpace_1,featureSpace_2,featureSpace_3,featureSpace_4]\n",
    "\n",
    "Nfeatures = 4\n",
    "MaxFeatureSize = 3\n",
    "treeChildren = -1*np.ones((Nfeatures,MaxFeatureSize),dtype=int)\n",
    "targetId = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = findRoot(data=data,labelId=targetId,cols=columnNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sex is the predicted root of the tree\n",
    "data_filtered = data\n",
    "cNode = root\n",
    "treeChildren = findNextNode(data=data_filtered,currentNode=cNode,featureSpace=featureSpace,labelId=targetId,treeChildren=treeChildren)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeChildren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. The next node after Sex=Male = PClass\n",
    "#2. The next node after Sex=Female = PClass (Does that mean the Sex feature is redundant?)\n",
    "data_filtered_SexMale = data[(data[:,3]==1)]\n",
    "cNode = 0 \n",
    "treeChildrenSexMale = findNextNode(data=data_filtered_SexMale,currentNode=cNode,featureSpace=featureSpace,labelId=targetId,treeChildren=treeChildren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeChildrenSexMale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is Sex redundant?\n",
    "print('Y|Pclass,Sex=Male')\n",
    "print(getEntropy(data=data,Y=targetId,X=0,Xgiven=[(3,0)]))\n",
    "print('Y|Pclass,Sex=Female')\n",
    "print(getEntropy(data=data,Y=targetId,X=0,Xgiven=[(3,1)]))\n",
    "print('Y is NOT conditionally independent of Sex, given Pclass!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. The next node after Sex=Male = PClass\n",
    "#2. The next node after Sex=Female = PClass (Does that mean the Sex feature is redundant?)\n",
    "data_filtered_SexFemale = data[(data[:,3]==0)]\n",
    "cNode = 0 \n",
    "treeChildrenSexFemale = findNextNode(data=data_filtered_SexFemale,currentNode=cNode,featureSpace=featureSpace,labelId=targetId,treeChildren=treeChildren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeChildrenSexFemale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. The next node after Sex=Male,PClass=0 = S/S\n",
    "#2.The next node after Sex=Male,PClass=1 = P/C\n",
    "#3.The next node after Sex=Male,PClass=2 = P/C\n",
    "#4. The next node after Sex=Female,PClass=0 = P/C\n",
    "#5.The next node after Sex=Female,PClass=1 = P/C\n",
    "#6.The next node after Sex=Female,PClass=2 = P/C\n",
    "\n",
    "data_filtered_SexMale_Pclass0 = data[(data[:,3]==1)&(data[:,0]==0)]\n",
    "cNode = 1 \n",
    "treeChildrenSexMale = findNextNode(data=data_filtered_SexMale_Pclass0,currentNode=cNode,featureSpace=featureSpace,labelId=targetId,treeChildren=treeChildrenSexMale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Y|Sex=Male,Pclass=0,P/C = None')\n",
    "print(getEntropy(data=data,Y=targetId,Xgiven=[(3,0),(0,0),(2,0)]))\n",
    "print('Y|Sex=Male,Pclass=0,P/C >0')\n",
    "print(getEntropy(data=data,Y=targetId,Xgiven=[(3,1),(0,0),(2,1)]))\n",
    "print('Y|Pclass=0,Sex=Male')\n",
    "print(getEntropy(data=data,Y=targetId,Xgiven=[(0,0),(3,1)]))\n",
    "print('Y|Pclass=1,Sex=Female')\n",
    "print(getEntropy(data=data,Y=targetId,Xgiven=[(0,1),(3,1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = 0\n",
    "# y_pred = np.zeros(data.shape[0])\n",
    "# for m in range(data.shape[0]):\n",
    "#     instance = data[m,:]\n",
    "#     pred = predict(instance,root,treeChildren)\n",
    "#     if pred == 111:\n",
    "#         y_pred[m]=1\n",
    "#     else:\n",
    "#         y_pred[m]=0\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error_rate = (y_pred-data[:,4]).sum()/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeChildrenSexMale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
