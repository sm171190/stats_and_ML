{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMMON METHODS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def update_parameters(w_old,grad,step_size):\n",
    "    w_new = w_old + step_size*grad\n",
    "    return w_new    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calculate_gradient(X,y,w,algorithm): \n",
    "    m = X.shape[0]\n",
    "    X_augmented = np.concatenate((np.ones((m,1)),X),axis=1)\n",
    "    if algorithm.lower() == 'logreg':        \n",
    "        error_in_estimate = y-(np.exp(X_augmented.dot(w))/(1+np.exp(X_augmented.dot(w))))\n",
    "    elif algorithm.lower() == 'linreg':\n",
    "        error_in_estimate = (y-X_augmented.dot(w))\n",
    "    else:\n",
    "        raise Exception('Algorithm type unclear!')        \n",
    "        \n",
    "    grad = (X_augmented.T).dot(error_in_estimate)\n",
    "    return grad\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def gradient_ascent(X,y,tolerance,w_start,step_size,algorithm):\n",
    "    \n",
    "    iteration = 0\n",
    "    w_current = w_start\n",
    "    current_grad = calculate_gradient(X,y,w_start,algorithm)    \n",
    "    current_grad_norm = np.linalg.norm(current_grad)\n",
    "    grad_norms = []\n",
    "    grad_norms.append(current_grad_norm)\n",
    "    \n",
    "    while current_grad_norm > tolerance:        \n",
    "        w_updated = update_parameters(w_current,current_grad,step_size)\n",
    "        w_current = w_updated        \n",
    "        current_grad = calculate_gradient(X,y,w_current,algorithm)\n",
    "        current_grad_norm = np.linalg.norm(current_grad)\n",
    "        grad_norms.append(current_grad_norm)\n",
    "        iteration +=1\n",
    "        print(f'Iteration: {iteration}. ||grad|| : {current_grad_norm}')\n",
    "    \n",
    "    plt.plot(list(range(iteration+1)),grad_norms)\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('Grad_Norm')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    return w_current        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def makePredictions(parameters_estimated,X,algorithm):    \n",
    "    X_augmented = np.concatenate((np.ones((X.shape[0],1)),X),axis=1) \n",
    "    if algorithm.lower() == 'logreg':\n",
    "        z = X_augmented.dot(parameters_estimated)   \n",
    "        locations = z>0\n",
    "        pred = locations.astype(int)\n",
    "    elif algorithm.lower() == 'linreg':        \n",
    "        pred = X_augmented.dot(parameters_estimated)\n",
    "    else:\n",
    "        raise Exception('Algorithm type unclear!')        \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate Data For Linear Regression\n",
    "def generateDataForLinReg(m,n,variance,d):\n",
    "    '''Output: X - mxn , the data-points with m instances and n features, with all points within an n-dimensonal box bounded between -d and d\n",
    "               y - nx1 , the labels, with y=f(x) + noise, noise is Normal(0,variance),\n",
    "                         f(x) = w0 + w1x1 + ... + wnxn\n",
    "               wts - (n+1)x1 the actual parameters of the line used (w0,...,wn)\n",
    "    '''\n",
    "    Z = d*(2*np.random.random((m,n)) - 1)\n",
    "    X = np.concatenate((np.ones((m,1)),Z),axis=1)\n",
    "    w = np.random.randn(n+1,1)\n",
    "#     noise = np.sqrt(variance)*np.random.randn(m,1)\n",
    "    noise_above = np.sqrt(variance)*np.random.randn(m//2,1)\n",
    "    noise_below = np.sqrt(variance)*np.random.randn(m//2,1)\n",
    "    noise = np.concatenate((noise_above,noise_below))\n",
    "#     print(noise.shape)\n",
    "    y = X.dot(w) + noise\n",
    "    if n==1:        \n",
    "        plt.plot(Z,X.dot(w),'-b')\n",
    "        plt.scatter(Z,y)\n",
    "        plt.grid()    \n",
    "        plt.xlabel('x1')\n",
    "        plt.ylabel('x2')        \n",
    "    return (Z,y,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotPredicted(X,y,params_estimated):\n",
    "    (m,n) = X.shape\n",
    "    if n>1:\n",
    "        raise Exception('Cannot plot multi-dimensional data!')    \n",
    "    X_augmented = np.concatenate((np.ones((m,1)),X),axis=1)\n",
    "    plt.plot(X,X_augmented.dot(params_estimated),'-b')\n",
    "    plt.scatter(X,y)\n",
    "    plt.grid()    \n",
    "    plt.title('Line of best fit')\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getRMSEscore(y_pred,y_actual):\n",
    "    Nsamples = y_pred.size\n",
    "    return np.sqrt(np.sum((y_pred-y_actual)**2/Nsamples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Set parameters for linear regression\n",
    "m=200\n",
    "n=1\n",
    "sigma = 2\n",
    "d=10\n",
    "XTrain,yTrain,theta_actual = generateDataForLinReg(m,n,sigma,d)\n",
    "X_augmented = np.concatenate((np.ones((m,1)),XTrain),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run Linear Regression\n",
    "tol = 1e-3\n",
    "n = XTrain.shape[1]\n",
    "w_0 = np.random.randn(n+1,1)\n",
    "step = 1e-5\n",
    "algorithm = 'linreg'\n",
    "w_estimate = gradient_ascent(XTrain,yTrain,tol,w_0,step,algorithm)\n",
    "print(f'Estimated optimal solution: {w_estimate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Make predictions\n",
    "y_pred_train = makePredictions(w_estimate,XTrain,algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Chek accuracy\n",
    "rmse = getRMSEscore(y_pred_train,yTrain)\n",
    "print(f'RMSE: {rmse}')\n",
    "plotPredicted(XTrain,yTrain,w_estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate Data For Logistic Regression\n",
    "def generateDataForLogReg():\n",
    "    data = loadmat('logRegData.mat')\n",
    "    XTrain = data['XTrain']\n",
    "    XTest = data['XTest']\n",
    "    yTrain = data['yTrain']\n",
    "    yTest = data['yTest']\n",
    "    n,p = XTrain.shape\n",
    "    m,temp = XTest.shape\n",
    "    print(f'n = {n}, p = {p}, m = {m}')\n",
    "    return(XTrain,yTrain,XTest,yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def getErrorRate(y_pred,y_actual):\n",
    "    Nsamples = y_pred.size\n",
    "    return np.sum(np.abs(y_pred-y_actual))/Nsamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusionMatrix(yPred,yActual):\n",
    "    '''\n",
    "    Returns the confusion matrix for all classes\n",
    "    INPUT: yPred,yActual, - 1xm numpy arrays\n",
    "    OUTPUT: ConfMat is a 2x2xK numpy array where ConfMat[0,0,k] are TP for class k,ConfMat[0,1,k] are FP for class k \n",
    "            ConfMat[1,0,k] are TN for class k and ConfMat[1,1,k] are FN for class k\n",
    "    '''\n",
    "    classes = np.unique(yActual)\n",
    "    K = classes.size\n",
    "    M = yActual.size\n",
    "    ConfMat = np.zeros((2,2,K))\n",
    "    for k in range(K):\n",
    "        for m in range(M):\n",
    "            if yActual[m]==k and yPred[m]==k : #True Positive\n",
    "                ConfMat[0,0,k]+=1\n",
    "            elif yActual[m]!=k and yPred[m]==k : #False Positive\n",
    "                ConfMat[0,1,k]+=1\n",
    "            elif yActual[m]!=k and yPred[m]!=k : #True Negative\n",
    "                ConfMat[1,0,k]+=1\n",
    "            else:\n",
    "                ConfMat[1,1,k]+=1\n",
    "    return ConfMat\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrecisionRecallF1Scores(confusionMat):\n",
    "    '''\n",
    "    Finds the Precision, Recall and the f1-score for all classes based on the confusion matrix\n",
    "    INPUT: confusionMaAt, a 2x2xK numpy array - confusion matrix\n",
    "    OUTPUT:scores is a 1x3xK numpy array where scores(0,0,k) is precision for class k , scores(0,1,k) is recall for class k and \n",
    "    scores(0,2,k) is f1-score for class k \n",
    "    '''\n",
    "    K = confusionMat.shape[2]\n",
    "    scores = np.zeros((1,3,K))\n",
    "    for k in range(K):\n",
    "        TP = confusionMat[0,0,k]\n",
    "        FP = confusionMat[0,1,k]\n",
    "        TN = confusionMat[1,0,k]\n",
    "        FN = confusionMat[1,1,k]\n",
    "        precision = TP/(TP+FP)\n",
    "        recall = TP/(TP+FN)\n",
    "        f1 = 2/((1/precision)+(1/recall))\n",
    "        scores[0,0,k] = precision\n",
    "        scores[0,1,k] = recall\n",
    "        scores[0,2,k] = f1\n",
    "    \n",
    "    return scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Set parameters for linear regression\n",
    "(XTrain,yTrain,XTest,yTest) = generateDataForLogReg()\n",
    "# csv_path = \"C://Users/saurmisr/Downloads/titanic.csv\"\n",
    "# data = pd.read_csv(csv_path)\n",
    "# X = data.drop(labels=['Survived','Name'],axis=1)\n",
    "# X['Sex']=X['Sex'].apply(lambda X:0 if X=='male' else 0)\n",
    "# y = data['Survived']\n",
    "# XTrain = X.to_numpy()\n",
    "# yTrain = y.to_numpy()\n",
    "# XTest = XTrain\n",
    "# yTest = yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run Logistic Regression\n",
    "\n",
    "tol = 1e-3\n",
    "p = XTrain.shape[1]\n",
    "w_0 = np.random.randn(p+1,1)\n",
    "step = 1e-4\n",
    "# w_0 = np.zeros((p+1,1))\n",
    "algorithm = 'logreg'\n",
    "w_estimate = gradient_ascent(XTrain,yTrain,tol,w_0,step,algorithm)\n",
    "print(f'Estimated optimal solution: {w_estimate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "algorithm = 'logreg'\n",
    "y_pred_train = makePredictions(w_estimate,XTrain,algorithm)\n",
    "y_pred_test = makePredictions(w_estimate,XTest,algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Check accuracy\n",
    "error_rate_train = getErrorRate(y_pred_train,yTrain)\n",
    "error_rate_test = getErrorRate(y_pred_test,yTest)\n",
    "print(f'Error rates : {(error_rate_train,error_rate_test)}')\n",
    "print(f'Success rates : {(1-error_rate_train,1-error_rate_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "CMat = getConfusionMatrix(y_pred_train,yTrain)\n",
    "scores = getPrecisionRecallF1Scores(CMat)\n",
    "print(f'PRECISION FOR Label 1: {scores[0,0,1]}')\n",
    "print(f'Recall FOR Label 1: {scores[0,1,1]}')\n",
    "print(f'f1-score FOR Label 1: {scores[0,2,1]}')\n",
    "print(f'PRECISION FOR Label 0: {scores[0,0,0]}')\n",
    "print(f'Recall FOR Label 0: {scores[0,1,0]}')\n",
    "print(f'f1-score FOR Label 0: {scores[0,2,0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
